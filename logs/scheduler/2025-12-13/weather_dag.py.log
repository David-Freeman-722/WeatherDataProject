[2025-12-13T00:51:16.273+0000] {processor.py:161} INFO - Started process (PID=8007) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T00:51:16.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T00:51:16.277+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:51:16.276+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:54:53.573+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:54:53.572+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T00:54:53.584+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:54:53.584+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T00:54:53.592+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:54:53.591+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T00:54:53.636+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:54:53.635+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:54:53.644+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:54:53.643+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:54:53.661+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:54:53.659+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:54:53.662+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:54:53.661+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T00:54:53.677+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:54:53.663+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T00:54:53.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:54:53.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 4.978 seconds
[2025-12-13T00:55:23.856+0000] {processor.py:161} INFO - Started process (PID=8076) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T00:55:23.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T00:55:23.860+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:23.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:55:25.372+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:25.371+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T00:55:25.377+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:25.376+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T00:55:25.377+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:25.377+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T00:55:25.392+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:25.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:55:25.396+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:25.396+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:55:25.401+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:25.400+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:55:25.402+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:25.401+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T00:55:25.407+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:25.402+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T00:55:25.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:55:25.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.603 seconds
[2025-12-13T00:55:55.935+0000] {processor.py:161} INFO - Started process (PID=8137) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T00:55:55.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T00:55:55.946+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:55.939+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:55:57.846+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:57.845+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T00:55:57.852+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:57.851+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T00:55:57.853+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:57.852+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T00:55:57.870+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:57.869+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:55:57.875+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:57.875+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:55:57.882+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:57.879+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:55:57.883+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:57.882+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T00:55:57.888+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:55:57.883+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T00:55:57.890+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:55:57.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.158 seconds
[2025-12-13T00:56:28.177+0000] {processor.py:161} INFO - Started process (PID=8202) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T00:56:28.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T00:56:28.181+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:56:28.180+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:56:29.812+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:56:29.811+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T00:56:29.816+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:56:29.815+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T00:56:29.816+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:56:29.816+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T00:56:29.829+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:56:29.829+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:56:29.834+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:56:29.833+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:56:30.351+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:56:29.838+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:56:30.351+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:56:30.351+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T00:56:30.356+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:56:30.352+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T00:56:30.357+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:56:30.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.223 seconds
[2025-12-13T00:57:01.135+0000] {processor.py:161} INFO - Started process (PID=8270) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T00:57:01.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T00:57:01.139+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:01.139+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:57:02.923+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:02.922+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T00:57:02.927+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:02.926+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T00:57:02.928+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:02.927+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T00:57:02.942+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:02.942+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:57:02.947+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:02.946+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:57:02.951+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:02.950+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:57:02.951+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:02.951+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T00:57:02.956+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:02.952+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T00:57:02.957+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:57:02.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.868 seconds
[2025-12-13T00:57:33.427+0000] {processor.py:161} INFO - Started process (PID=8335) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T00:57:33.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T00:57:33.431+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:33.430+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:57:35.342+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:35.341+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T00:57:35.348+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:35.347+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T00:57:35.349+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:35.348+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T00:57:35.368+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:35.368+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:57:35.373+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:35.372+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:57:35.377+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:35.376+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:57:35.378+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:35.378+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T00:57:35.384+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:57:35.379+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T00:57:35.386+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:57:35.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.017 seconds
[2025-12-13T00:58:05.918+0000] {processor.py:161} INFO - Started process (PID=8398) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T00:58:05.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T00:58:05.925+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:05.923+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:58:07.946+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:07.946+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T00:58:07.954+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:07.953+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T00:58:07.955+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:07.955+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T00:58:07.974+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:07.973+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:58:07.980+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:07.979+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:58:07.988+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:07.987+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:58:07.989+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:07.989+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T00:58:07.996+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:07.990+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T00:58:07.998+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:58:08.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.161 seconds
[2025-12-13T00:58:38.485+0000] {processor.py:161} INFO - Started process (PID=8466) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T00:58:38.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T00:58:38.492+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:38.491+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:58:40.727+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:40.727+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T00:58:40.731+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:40.730+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T00:58:40.731+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:40.731+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T00:58:40.753+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:40.753+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:58:40.757+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:40.757+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:58:40.761+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:40.761+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:58:40.762+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:40.762+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T00:58:40.780+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:58:40.762+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T00:58:40.782+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:58:40.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.352 seconds
[2025-12-13T00:59:11.198+0000] {processor.py:161} INFO - Started process (PID=8534) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T00:59:11.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T00:59:11.203+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:11.202+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:59:13.621+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:13.619+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T00:59:13.626+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:13.625+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T00:59:13.626+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:13.626+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T00:59:13.646+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:13.645+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:59:13.651+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:13.650+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:59:13.656+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:13.655+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:59:13.657+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:13.656+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T00:59:13.663+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:13.657+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T00:59:13.664+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:59:13.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.520 seconds
[2025-12-13T00:59:44.431+0000] {processor.py:161} INFO - Started process (PID=8598) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T00:59:44.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T00:59:44.436+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:44.435+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:59:46.473+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:46.472+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T00:59:46.477+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:46.476+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T00:59:46.477+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:46.477+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T00:59:46.489+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:46.489+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:59:46.493+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:46.493+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:59:46.497+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:46.497+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T00:59:46.498+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:46.498+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T00:59:46.503+0000] {logging_mixin.py:188} INFO - [2025-12-13T00:59:46.498+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T00:59:46.504+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T00:59:46.535+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.118 seconds
[2025-12-13T01:00:16.755+0000] {processor.py:161} INFO - Started process (PID=8667) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:00:16.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:00:16.760+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:16.759+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:00:18.777+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:18.777+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:00:18.782+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:18.781+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:00:18.782+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:18.782+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:00:18.795+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:18.795+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:00:18.800+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:18.799+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:00:18.804+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:18.803+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:00:18.805+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:18.805+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:00:18.811+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:18.805+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:00:18.813+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:00:18.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.103 seconds
[2025-12-13T01:00:48.952+0000] {processor.py:161} INFO - Started process (PID=8733) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:00:48.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:00:48.957+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:48.957+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:00:51.081+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:51.081+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:00:51.085+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:51.085+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:00:51.086+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:51.085+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:00:51.097+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:51.096+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:00:51.100+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:51.100+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:00:51.103+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:51.103+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:00:51.104+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:51.104+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:00:51.109+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:00:51.104+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:00:51.110+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:00:51.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.202 seconds
[2025-12-13T01:01:21.247+0000] {processor.py:161} INFO - Started process (PID=8793) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:01:21.250+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:01:21.252+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:21.251+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:01:23.169+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:23.169+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:01:23.173+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:23.173+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:01:23.174+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:23.173+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:01:23.188+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:23.188+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:01:23.192+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:23.191+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:01:23.197+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:23.195+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:01:23.197+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:23.197+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:01:23.206+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:23.198+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:01:23.207+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:01:23.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.007 seconds
[2025-12-13T01:01:53.483+0000] {processor.py:161} INFO - Started process (PID=8855) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:01:53.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:01:53.487+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:53.486+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:01:55.229+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:55.229+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:01:55.232+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:55.232+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:01:55.233+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:55.233+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:01:55.246+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:55.246+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:01:55.251+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:55.250+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:01:55.255+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:55.255+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:01:55.256+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:55.256+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:01:55.263+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:01:55.256+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:01:55.265+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:01:55.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.826 seconds
[2025-12-13T01:06:31.727+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:06:31.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:06:31.738+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:06:31.737+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:06:37.141+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:06:37.140+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:06:37.146+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:06:37.146+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:06:37.147+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:06:37.147+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:06:37.192+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:06:37.191+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:06:37.197+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:06:37.196+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:06:37.201+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:06:37.201+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:06:37.202+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:06:37.202+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:06:37.212+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:06:37.203+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:06:37.214+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:06:37.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 5.551 seconds
[2025-12-13T01:07:08.158+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:07:08.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:07:08.164+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:08.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:07:09.732+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:09.731+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:07:09.738+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:09.737+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:07:09.738+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:09.738+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:07:09.753+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:09.753+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:07:09.756+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:09.756+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:07:09.759+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:09.758+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:07:09.759+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:09.759+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:07:09.764+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:09.760+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:07:09.766+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:07:09.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.654 seconds
[2025-12-13T01:07:40.470+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:07:40.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:07:40.477+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:40.476+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:07:42.161+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:42.160+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:07:42.164+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:42.164+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:07:42.165+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:42.165+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:07:42.181+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:42.180+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:07:42.184+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:42.183+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:07:42.187+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:42.187+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:07:42.188+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:42.188+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:07:42.195+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:07:42.189+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:07:42.197+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:07:42.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.777 seconds
[2025-12-13T01:08:12.728+0000] {processor.py:161} INFO - Started process (PID=271) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:08:12.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:08:12.735+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:12.735+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:08:14.207+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:14.207+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:08:14.211+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:14.210+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:08:14.211+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:14.211+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:08:14.224+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:14.224+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:08:14.227+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:14.227+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:08:14.231+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:14.230+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:08:14.232+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:14.231+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:08:14.237+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:14.232+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:08:14.238+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:08:14.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.560 seconds
[2025-12-13T01:08:44.648+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:08:44.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:08:44.658+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:44.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:08:46.593+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:46.592+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:08:46.597+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:46.597+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:08:46.598+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:46.598+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:08:46.618+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:46.618+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:08:46.623+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:46.622+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:08:46.627+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:46.626+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:08:46.628+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:46.627+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:08:46.634+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:08:46.628+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:08:46.636+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:08:46.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.066 seconds
[2025-12-13T01:09:16.834+0000] {processor.py:161} INFO - Started process (PID=402) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:09:16.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:09:16.842+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:16.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:09:18.605+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:18.605+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:09:18.610+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:18.609+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:09:18.610+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:18.610+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:09:18.635+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:18.635+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:09:18.638+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:18.638+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:09:18.642+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:18.641+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:09:18.643+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:18.643+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:09:18.648+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:18.643+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:09:18.649+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:09:18.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.877 seconds
[2025-12-13T01:09:48.834+0000] {processor.py:161} INFO - Started process (PID=462) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:09:48.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:09:48.841+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:48.840+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:09:50.402+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:50.402+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:09:50.406+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:50.405+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:09:50.406+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:50.406+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:09:50.420+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:50.419+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:09:50.423+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:50.423+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:09:50.427+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:50.426+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:09:50.427+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:50.427+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:09:50.433+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:09:50.428+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:09:50.434+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:09:50.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.647 seconds
[2025-12-13T01:10:20.958+0000] {processor.py:161} INFO - Started process (PID=527) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:10:20.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:10:20.965+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:20.964+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:10:22.529+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:22.529+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:10:22.536+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:22.535+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:10:22.536+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:22.536+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:10:22.557+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:22.557+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:10:22.561+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:22.560+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:10:22.565+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:22.564+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:10:22.566+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:22.565+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:10:22.576+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:22.566+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:10:22.578+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:10:22.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.682 seconds
[2025-12-13T01:10:52.941+0000] {processor.py:161} INFO - Started process (PID=593) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:10:52.944+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:10:52.948+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:52.947+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:10:54.370+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:54.369+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:10:54.374+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:54.373+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:10:54.374+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:54.374+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:10:54.388+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:54.388+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:10:54.392+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:54.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:10:54.396+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:54.395+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:10:54.397+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:54.396+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:10:54.402+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:10:54.397+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:10:54.403+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:10:54.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.685 seconds
[2025-12-13T01:11:24.514+0000] {processor.py:161} INFO - Started process (PID=665) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:11:24.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:11:24.520+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:24.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:11:26.285+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:26.284+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:11:26.288+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:26.287+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:11:26.288+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:26.288+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:11:26.299+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:26.299+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:11:26.302+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:26.302+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:11:26.305+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:26.305+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:11:26.306+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:26.306+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:11:26.310+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:26.306+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:11:26.311+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:11:26.343+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.841 seconds
[2025-12-13T01:11:56.421+0000] {processor.py:161} INFO - Started process (PID=731) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:11:56.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:11:56.427+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:56.426+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:11:58.176+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:58.176+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:11:58.181+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:58.180+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:11:58.182+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:58.181+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:11:58.199+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:58.198+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:11:58.203+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:58.203+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:11:58.208+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:58.207+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:11:58.209+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:58.208+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:11:58.214+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:11:58.209+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:11:58.215+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:11:58.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.846 seconds
[2025-12-13T01:12:28.931+0000] {processor.py:161} INFO - Started process (PID=791) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:12:28.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:12:28.936+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:12:28.935+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:12:30.457+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:12:30.457+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:12:30.461+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:12:30.460+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:12:30.461+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:12:30.461+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:12:30.476+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:12:30.476+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:12:30.479+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:12:30.479+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:12:30.483+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:12:30.482+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2025-12-13T01:12:30.483+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:12:30.483+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2025-12-13T01:12:30.488+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:12:30.483+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 268, in __init__
    project = self._determine_default(project)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 287, in _determine_default
    return _determine_default_project(project)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/_helpers/__init__.py", line 152, in _determine_default_project
    _, project = google.auth.default()
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2025-12-13T01:12:30.489+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:12:30.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.605 seconds
[2025-12-13T01:14:18.661+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:14:18.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:14:18.679+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:18.676+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:14:22.959+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:22.957+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:14:22.964+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:22.964+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:14:22.965+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:22.965+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:14:23.035+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:23.034+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:14:23.042+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:23.036+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:14:23.044+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:14:23.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 4.626 seconds
[2025-12-13T01:14:53.370+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:14:53.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:14:53.400+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:53.399+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:14:54.835+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:54.834+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:14:54.838+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:54.837+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:14:54.838+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:54.838+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:14:54.850+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:54.850+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:14:54.855+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:14:54.850+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:14:54.856+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:14:54.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.533 seconds
[2025-12-13T01:15:25.076+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:15:25.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:15:25.083+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:25.082+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:15:27.072+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:27.071+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:15:27.075+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:27.075+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:15:27.076+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:27.075+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:15:27.087+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:27.086+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:15:27.091+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:27.087+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:15:27.092+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:15:27.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.064 seconds
[2025-12-13T01:15:57.811+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:15:57.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:15:57.818+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:57.817+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:15:59.332+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:59.331+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:15:59.335+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:59.334+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:15:59.335+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:59.335+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:15:59.346+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:59.346+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:15:59.350+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:15:59.346+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:15:59.351+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:15:59.383+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.586 seconds
[2025-12-13T01:16:29.532+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:16:29.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:16:29.539+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:16:29.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:16:31.228+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:16:31.228+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:16:31.232+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:16:31.232+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:16:31.233+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:16:31.233+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:16:31.248+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:16:31.247+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:16:31.258+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:16:31.249+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:16:31.259+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:16:31.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.782 seconds
[2025-12-13T01:17:02.177+0000] {processor.py:161} INFO - Started process (PID=410) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:17:02.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:17:02.184+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:17:02.183+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:17:04.062+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:17:04.062+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:17:04.065+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:17:04.065+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:17:04.066+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:17:04.066+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:17:04.095+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:17:04.094+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:17:04.102+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:17:04.095+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:17:04.104+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:17:04.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.013 seconds
[2025-12-13T01:19:03.521+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:19:03.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:19:03.532+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:19:03.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:19:07.900+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:19:07.900+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:19:07.905+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:19:07.905+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:19:07.906+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:19:07.906+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:19:07.940+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:19:07.939+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:19:33.372+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:19:33.371+0000] {timeout.py:68} ERROR - Process timed out, PID: 76
[2025-12-13T01:20:03.990+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:20:03.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:20:03.999+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:20:03.998+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:20:06.176+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:20:06.176+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:20:06.182+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:20:06.181+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:20:06.182+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:20:06.182+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:20:06.210+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:20:06.210+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:20:33.845+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:20:33.845+0000] {timeout.py:68} ERROR - Process timed out, PID: 195
[2025-12-13T01:21:04.114+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:21:04.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:21:04.121+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:21:04.120+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:21:05.902+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:21:05.901+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:21:05.905+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:21:05.905+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:21:05.905+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:21:05.905+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:21:05.917+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:21:05.917+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:21:33.958+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:21:33.957+0000] {timeout.py:68} ERROR - Process timed out, PID: 314
[2025-12-13T01:22:04.308+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:22:04.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:22:04.316+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:22:04.315+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:22:05.823+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:22:05.822+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:22:05.826+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:22:05.826+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:22:05.827+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:22:05.826+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:22:05.839+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:22:05.838+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:22:34.385+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:22:34.384+0000] {timeout.py:68} ERROR - Process timed out, PID: 433
[2025-12-13T01:23:05.010+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:23:05.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:23:05.017+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:23:05.016+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:23:06.452+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:23:06.452+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:23:06.455+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:23:06.455+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:23:06.456+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:23:06.455+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:23:06.467+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:23:06.466+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:23:34.854+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:23:34.854+0000] {timeout.py:68} ERROR - Process timed out, PID: 552
[2025-12-13T01:25:01.825+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:25:01.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:25:01.837+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:25:01.836+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:25:06.448+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:25:06.447+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:25:06.456+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:25:06.455+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:25:06.457+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:25:06.457+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:25:06.504+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:25:06.503+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:25:31.679+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:25:31.678+0000] {timeout.py:68} ERROR - Process timed out, PID: 76
[2025-12-13T01:26:02.122+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:26:02.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:26:02.132+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:26:02.131+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:26:03.742+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:26:03.742+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:26:03.745+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:26:03.745+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:26:03.746+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:26:03.745+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:26:03.759+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:26:03.758+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:26:31.974+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:26:31.971+0000] {timeout.py:68} ERROR - Process timed out, PID: 195
[2025-12-13T01:27:02.536+0000] {processor.py:161} INFO - Started process (PID=315) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:27:02.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:27:02.544+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:27:02.543+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:27:04.304+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:27:04.303+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:27:04.307+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:27:04.307+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:27:04.308+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:27:04.308+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:27:04.321+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:27:04.321+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:27:32.392+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:27:32.390+0000] {timeout.py:68} ERROR - Process timed out, PID: 315
[2025-12-13T01:31:50.028+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:31:50.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:31:50.037+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:31:50.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:31:54.845+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:31:54.844+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:31:54.851+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:31:54.851+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:31:54.852+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:31:54.852+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:31:54.889+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:31:54.888+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:31:55.745+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:31:55.738+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:31:55.746+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:31:55.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 5.776 seconds
[2025-12-13T01:32:26.203+0000] {processor.py:161} INFO - Started process (PID=145) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:32:26.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:32:26.210+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:32:26.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:32:27.735+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:32:27.734+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:32:27.739+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:32:27.738+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:32:27.740+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:32:27.739+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:32:27.755+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:32:27.755+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:32:28.332+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:32:28.326+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:32:28.334+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:32:28.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.177 seconds
[2025-12-13T01:32:58.593+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:32:58.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:32:58.600+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:32:58.599+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:33:00.258+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:00.258+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:33:00.262+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:00.261+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:33:00.262+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:00.262+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:33:00.276+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:00.275+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:33:00.824+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:00.816+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:33:00.826+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:33:00.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.284 seconds
[2025-12-13T01:33:31.806+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:33:31.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:33:31.812+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:31.812+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:33:33.346+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:33.345+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:33:33.349+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:33.349+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:33:33.350+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:33.350+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:33:33.363+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:33.363+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:33:33.947+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:33:33.941+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:33:33.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:33:33.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.188 seconds
[2025-12-13T01:34:04.147+0000] {processor.py:161} INFO - Started process (PID=352) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:34:04.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:34:04.155+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:04.155+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:34:05.708+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:05.707+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:34:05.712+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:05.712+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:34:05.713+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:05.713+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:34:05.760+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:05.759+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:34:06.363+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:06.358+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:34:06.364+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:34:06.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.268 seconds
[2025-12-13T01:34:36.726+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:34:36.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:34:36.732+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:36.732+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:34:38.301+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:38.300+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:34:38.304+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:38.304+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:34:38.305+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:38.304+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:34:38.317+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:38.316+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:34:38.952+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:34:38.946+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:34:38.953+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:34:38.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.274 seconds
[2025-12-13T01:39:24.294+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:39:24.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:39:24.303+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:39:24.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:39:28.797+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:39:28.796+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:39:28.803+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:39:28.802+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:39:28.803+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:39:28.803+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:39:28.841+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:39:28.840+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:39:28.849+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:39:28.842+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:39:28.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:39:28.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 4.609 seconds
[2025-12-13T01:39:59.174+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:39:59.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:39:59.191+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:39:59.191+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:40:03.308+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:03.308+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:40:03.311+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:03.311+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:40:03.312+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:03.312+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:40:03.325+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:03.324+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:40:03.330+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:03.325+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:40:03.331+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:40:03.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 4.206 seconds
[2025-12-13T01:40:33.620+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:40:33.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:40:33.627+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:33.626+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:40:35.115+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:35.115+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:40:35.118+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:35.118+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:40:35.119+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:35.119+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:40:35.132+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:35.132+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:40:35.138+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:40:35.133+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:40:35.139+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:40:35.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.567 seconds
[2025-12-13T01:41:05.504+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:41:05.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:41:05.511+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:05.510+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:41:07.594+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:07.594+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:41:07.600+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:07.599+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:41:07.600+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:07.600+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:41:07.613+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:07.612+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:41:07.617+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:07.613+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:41:07.618+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:41:07.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.161 seconds
[2025-12-13T01:41:37.796+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:41:37.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:41:37.803+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:37.803+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:41:39.425+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:39.425+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:41:39.429+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:39.429+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:41:39.430+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:39.429+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:41:39.442+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:39.441+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:41:39.446+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:41:39.442+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:41:39.447+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:41:39.485+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.703 seconds
[2025-12-13T01:42:09.740+0000] {processor.py:161} INFO - Started process (PID=423) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:42:09.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:42:09.749+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:09.748+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:42:11.416+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:11.415+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:42:11.419+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:11.418+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:42:11.419+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:11.419+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:42:11.431+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:11.431+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:42:11.435+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:11.432+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:42:11.437+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:42:11.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.745 seconds
[2025-12-13T01:42:41.898+0000] {processor.py:161} INFO - Started process (PID=491) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:42:41.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:42:41.905+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:41.905+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:42:43.218+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:43.217+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:42:43.221+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:43.220+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:42:43.221+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:43.221+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:42:43.233+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:43.233+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:42:43.238+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:42:43.234+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:42:43.239+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:42:43.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.562 seconds
[2025-12-13T01:43:14.165+0000] {processor.py:161} INFO - Started process (PID=553) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:43:14.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:43:14.172+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:14.171+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:43:15.696+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:15.696+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:43:15.701+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:15.701+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:43:15.702+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:15.702+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:43:15.732+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:15.731+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:43:15.742+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:15.733+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:43:15.746+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:43:15.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.659 seconds
[2025-12-13T01:43:46.812+0000] {processor.py:161} INFO - Started process (PID=614) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:43:46.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:43:46.819+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:46.818+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:43:48.308+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:48.307+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:43:48.311+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:48.311+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:43:48.312+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:48.311+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:43:48.324+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:48.324+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:43:48.329+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:43:48.325+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:43:48.330+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:43:48.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.567 seconds
[2025-12-13T01:44:18.681+0000] {processor.py:161} INFO - Started process (PID=677) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:44:18.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:44:18.688+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:18.688+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:44:20.247+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:20.246+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:44:20.250+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:20.249+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:44:20.250+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:20.250+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:44:20.261+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:20.261+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:44:20.265+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:20.262+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:44:20.266+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:44:20.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.628 seconds
[2025-12-13T01:44:50.592+0000] {processor.py:161} INFO - Started process (PID=738) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:44:50.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:44:50.600+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:50.599+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:44:52.684+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:52.684+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:44:52.688+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:52.687+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:44:52.688+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:52.688+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:44:52.703+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:52.703+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:44:52.708+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:44:52.704+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:44:52.709+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:44:52.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.164 seconds
[2025-12-13T01:48:43.274+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:48:43.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:48:43.283+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:48:43.282+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:48:48.274+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:48:48.273+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:48:48.278+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:48:48.277+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:48:48.278+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:48:48.278+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:48:48.312+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:48:48.311+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:48:48.318+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:48:48.312+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:48:48.320+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:48:48.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 5.096 seconds
[2025-12-13T01:49:18.649+0000] {processor.py:161} INFO - Started process (PID=144) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:49:18.652+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:49:18.657+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:18.656+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:49:20.662+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:20.661+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:49:20.665+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:20.665+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:49:20.665+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:20.665+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:49:20.678+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:20.677+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:49:20.682+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:20.678+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:49:20.683+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:49:20.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.080 seconds
[2025-12-13T01:49:50.866+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:49:50.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:49:50.871+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:50.871+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:49:52.535+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:52.535+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:49:52.538+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:52.538+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:49:52.539+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:52.538+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:49:52.555+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:52.555+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:49:52.561+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:49:52.556+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:49:52.562+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:49:52.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.753 seconds
[2025-12-13T01:50:22.819+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:50:22.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:50:22.827+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:22.826+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:50:24.420+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:24.419+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:50:24.424+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:24.423+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:50:24.424+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:24.424+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:50:24.438+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:24.437+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:50:24.444+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:24.438+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:50:24.445+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:50:24.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.803 seconds
[2025-12-13T01:50:54.755+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:50:54.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:50:54.765+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:54.765+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:50:56.591+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:56.590+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:50:56.597+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:56.597+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:50:56.598+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:56.598+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:50:56.611+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:56.611+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:50:56.618+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:50:56.611+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:50:56.620+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:50:56.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.918 seconds
[2025-12-13T01:51:26.927+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:51:26.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:51:26.935+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:51:26.935+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:51:28.561+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:51:28.561+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:51:28.565+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:51:28.564+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:51:28.565+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:51:28.565+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:51:28.577+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:51:28.577+0000] {_default.py:683} WARNING - No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable
[2025-12-13T01:51:28.582+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:51:28.578+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 116, in load_csv_data_into_gbq
    client = bigquery.Client()
             ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 241, in __init__
    super(Client, self).__init__(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 320, in __init__
    _ClientProjectMixin.__init__(self, project=project, credentials=credentials)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/client/__init__.py", line 271, in __init__
    raise EnvironmentError(
OSError: Project was not passed and could not be determined from the environment.
[2025-12-13T01:51:28.584+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:51:28.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.705 seconds
[2025-12-13T01:57:22.054+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:57:22.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:57:22.065+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:57:22.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:57:27.825+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:57:27.825+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:57:27.830+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:57:27.829+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:57:27.830+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:57:27.830+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:57:27.868+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:57:27.867+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:57:28.767+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:57:28.758+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:57:28.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:57:28.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 6.766 seconds
[2025-12-13T01:57:59.709+0000] {processor.py:161} INFO - Started process (PID=147) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:57:59.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:57:59.716+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:57:59.715+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:58:01.232+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:01.231+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:58:01.236+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:01.236+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:58:01.237+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:01.236+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:58:01.250+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:01.250+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:58:01.812+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:01.805+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:58:01.814+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:58:01.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.151 seconds
[2025-12-13T01:58:32.128+0000] {processor.py:161} INFO - Started process (PID=218) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:58:32.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:58:32.134+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:32.134+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:58:33.765+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:33.764+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:58:33.769+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:33.769+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:58:33.770+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:33.769+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:58:33.785+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:33.785+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:58:34.453+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:58:34.447+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:58:34.454+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:58:34.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.377 seconds
[2025-12-13T01:59:04.925+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:59:04.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:59:04.974+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:04.973+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:59:06.402+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:06.401+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:59:06.409+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:06.408+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:59:06.410+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:06.410+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:59:06.429+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:06.428+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:59:07.690+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:07.684+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:59:07.692+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:59:07.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.998 seconds
[2025-12-13T01:59:37.810+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T01:59:37.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T01:59:37.817+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:37.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:59:39.328+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:39.327+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T01:59:39.331+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:39.331+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T01:59:39.332+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:39.332+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T01:59:39.344+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:39.344+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T01:59:39.953+0000] {logging_mixin.py:188} INFO - [2025-12-13T01:59:39.946+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T01:59:39.955+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T01:59:39.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.199 seconds
[2025-12-13T02:00:10.521+0000] {processor.py:161} INFO - Started process (PID=430) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:00:10.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:00:10.555+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:10.554+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:00:12.894+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:12.893+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:00:12.897+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:12.896+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:00:12.897+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:12.897+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:00:12.907+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:12.907+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:00:13.542+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:13.534+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:00:13.543+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:00:13.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 3.084 seconds
[2025-12-13T02:00:43.860+0000] {processor.py:161} INFO - Started process (PID=493) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:00:43.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:00:43.866+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:43.865+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:00:45.362+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:45.361+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:00:45.367+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:45.366+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:00:45.368+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:45.367+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:00:45.383+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:45.383+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:00:46.237+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:00:46.230+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:00:46.238+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:00:46.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.425 seconds
[2025-12-13T02:01:16.461+0000] {processor.py:161} INFO - Started process (PID=554) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:01:16.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:01:16.468+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:16.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:01:18.126+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:18.126+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:01:18.129+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:18.129+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:01:18.130+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:18.129+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:01:18.142+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:18.142+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:01:18.970+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:18.963+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:01:18.971+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:01:19.012+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.565 seconds
[2025-12-13T02:01:49.160+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:01:49.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:01:49.168+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:49.167+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:01:50.800+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:50.799+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:01:50.804+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:50.803+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:01:50.804+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:50.804+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:01:50.820+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:50.819+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:01:51.506+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:01:51.500+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:01:51.507+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:01:51.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.409 seconds
[2025-12-13T02:02:22.030+0000] {processor.py:161} INFO - Started process (PID=682) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:02:22.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:02:22.038+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:22.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:02:23.512+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:23.511+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:02:23.516+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:23.515+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:02:23.517+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:23.516+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:02:23.529+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:23.529+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:02:24.222+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:24.217+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:02:24.224+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:02:24.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.246 seconds
[2025-12-13T02:02:54.426+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:02:54.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:02:54.463+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:54.463+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:02:55.959+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:55.959+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:02:55.962+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:55.962+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:02:55.963+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:55.962+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:02:55.973+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:55.973+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:02:56.654+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:02:56.648+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:02:56.656+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:02:56.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.281 seconds
[2025-12-13T02:03:26.833+0000] {processor.py:161} INFO - Started process (PID=805) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:03:26.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:03:26.842+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:03:26.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:03:28.377+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:03:28.376+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:03:28.380+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:03:28.380+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:03:28.380+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:03:28.380+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:03:28.389+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:03:28.387+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id)
TypeError: load_csv_data_into_gbq() missing 1 required positional argument: 'project_id'
[2025-12-13T02:03:28.390+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:03:28.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 1.614 seconds
[2025-12-13T02:03:58.870+0000] {processor.py:161} INFO - Started process (PID=865) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:03:58.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:03:58.909+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:03:58.908+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:04:00.428+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:04:00.428+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:04:00.432+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:04:00.431+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:04:00.432+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:04:00.432+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:04:00.443+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:04:00.443+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:04:01.216+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:04:01.211+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id, project)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:04:01.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:04:01.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.401 seconds
[2025-12-13T02:06:24.050+0000] {processor.py:161} INFO - Started process (PID=79) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:06:24.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:06:24.060+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:06:24.059+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:06:28.942+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:06:28.941+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:06:28.947+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:06:28.947+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:06:28.948+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:06:28.947+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:06:28.986+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:06:28.985+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:06:29.668+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:06:29.661+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id, project)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:06:29.670+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:06:29.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 5.678 seconds
[2025-12-13T02:07:00.117+0000] {processor.py:161} INFO - Started process (PID=147) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:07:00.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:07:00.126+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:00.125+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:07:01.719+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:01.718+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:07:01.722+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:01.721+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:07:01.722+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:01.722+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:07:01.734+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:01.734+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:07:02.295+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:02.288+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id, project)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:07:02.297+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:07:02.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.230 seconds
[2025-12-13T02:07:32.777+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:07:32.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:07:32.784+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:32.784+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:07:34.088+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:34.088+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:07:34.092+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:34.092+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:07:34.093+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:34.093+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:07:34.109+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:34.108+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:07:34.747+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:07:34.741+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id, project)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:07:34.749+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:07:34.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.212 seconds
[2025-12-13T02:08:04.923+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:08:04.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:08:04.931+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:04.930+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:08:06.723+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:06.723+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:08:06.726+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:06.726+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:08:06.727+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:06.727+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:08:06.739+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:06.738+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:08:07.433+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:07.427+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id, project)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:08:07.434+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:08:07.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.557 seconds
[2025-12-13T02:08:37.552+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:08:37.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:08:37.558+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:37.558+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:08:39.115+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:39.114+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:08:39.120+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:39.119+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:08:39.121+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:39.120+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:08:39.141+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:39.140+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:08:39.722+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:08:39.714+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id, project)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:08:39.724+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:08:39.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.230 seconds
[2025-12-13T02:09:10.643+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/weather_dag.py
[2025-12-13T02:09:10.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/weather_dag.py for tasks to queue
[2025-12-13T02:09:10.650+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:09:10.649+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:09:12.141+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:09:12.141+0000] {get_raw_data.py:67} INFO - Yesterday's weather data retreived.
[2025-12-13T02:09:12.144+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:09:12.144+0000] {get_raw_data.py:90} INFO - Processing 1 rows of weather data...
[2025-12-13T02:09:12.145+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:09:12.145+0000] {get_raw_data.py:111} INFO - Finished processing 1 rows of weather data.
[2025-12-13T02:09:12.157+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:09:12.157+0000] {get_raw_data.py:124} INFO - Loading data into GBQ...
[2025-12-13T02:09:12.947+0000] {logging_mixin.py:188} INFO - [2025-12-13T02:09:12.941+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/weather_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2580, in load_table_from_file
    response = self._do_resumable_upload(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3000, in _do_resumable_upload
    upload, transport = self._initiate_resumable_upload(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 3069, in _initiate_resumable_upload
    upload.initiate(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 420, in initiate
    return _request_helpers.wait_and_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py", line 155, in wait_and_retry
    response = func()
               ^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/requests/upload.py", line 416, in retriable_request
    self._process_initiate_response(result)
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_upload.py", line 518, in _process_initiate_response
    _helpers.require_status_code(
  File "/home/airflow/.local/lib/python3.11/site-packages/google/resumable_media/_helpers.py", line 108, in require_status_code
    raise common.InvalidResponse(
google.resumable_media.common.InvalidResponse: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/weather_dag.py", line 7, in <module>
    from get_raw_data import run_daily_weather_pipeline
  File "/opt/airflow/dags/get_raw_data.py", line 137, in <module>
    run_daily_weather_pipeline()
  File "/opt/airflow/dags/get_raw_data.py", line 60, in run_daily_weather_pipeline
    load_csv_data_into_gbq(csv_file_name, full_table_id, project)
  File "/opt/airflow/dags/get_raw_data.py", line 126, in load_csv_data_into_gbq
    job = client.load_table_from_file(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/google/cloud/bigquery/client.py", line 2588, in load_table_from_file
    raise exceptions.from_http_response(exc.response)
google.api_core.exceptions.BadRequest: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/focused-stacker-479517-r8/jobs?uploadType=resumable: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[2025-12-13T02:09:12.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/weather_dag.py
[2025-12-13T02:09:12.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/weather_dag.py took 2.349 seconds
